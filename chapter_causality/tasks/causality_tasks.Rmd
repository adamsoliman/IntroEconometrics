---
title: "Intro to Causality - Tasks"
author: "Dr. Soliman"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)

```

## Task 1: SDO, ATE and Randomization

Let's compute these various quantities and biases with some toy data (i.e. data we generated ourselves).

1\. Load the data [here](https://www.dropbox.com/scl/fi/7gtkp7t1j0a1f7mec6qid/toy_data_2.csv?rlkey=wztw8nxs83kkqudh8j84nzv7i&dl=1). The `group` variable corresponds to whether the individual has been treated or not, the `Y0` variable corresponds to the potential outcome if the individual does not receive the treatment $(Y_i^0)$ while `Y1` corresponds to the potential outcome if the individual receives the treatment $(Y_i^1)$. Create a new variable containing the observed outcome $(Y_i)$ and the individual treatment effect $(\delta_i)$. (Recall that $Y_i = D_i * Y_i^1 + (1 - D_i) Y_i^0$ and $\delta_i = Y_i^1 - Y_i^0$.)

```{r}
# via your local folder (you'd need to change the path)
toy_data <- read.csv("/Users/adamsoliman/Library/CloudStorage/Dropbox/Clemson/Econometrics Course/data for tasks/toy_data_2.csv")

toy_data <- toy_data %>%
    mutate(Y = Y1 * group_dummy + (1 - group_dummy) * Y0,
           delta = Y1 - Y0)
```

2\. Compute the ***ATE*** and the ***SDO***. Is there is any *bias*? Is it large in magnitude?

```{r}
ATE = mean(toy_data$delta)
ATE

SDO = mean(toy_data$Y[toy_data$group == "treatment"]) - mean(toy_data$Y[toy_data$group == "control"])
SDO
```

The SDO is about 50% larger than the ATE, implying that the bias is quite large.

3\. In this new [dataset](https://www.dropbox.com/scl/fi/1r9okb2nchnzzoilv35bh/toy_data_random.csv?rlkey=m1anlbcq2wku4wmvvv5z2f0sw&dl=1) we've randomly assigned the same individuals to the treatment and control groups. Compute the ***SDO under randomization***. Remember that you need to recompute $Y_i$ because the assignment is not the same anymore. If you got it right, the bias should be very close to 0. Why is it not exactly 0? 

```{r}
toy_data_random <- read.csv("https://www.dropbox.com/scl/fi/1r9okb2nchnzzoilv35bh/toy_data_random.csv?rlkey=m1anlbcq2wku4wmvvv5z2f0sw&dl=1")

toy_data_random <- toy_data_random %>%
    mutate(Y = Y1 * group_random_dummy + (1 - group_random_dummy) * Y0)

SDO_random = mean(toy_data_random$Y[toy_data_random$group_random == "treatment"]) - mean(toy_data_random$Y[toy_data_random$group_random == "control"])
SDO_random

ATE - SDO_random
```

The bias is equal to `r round(ATE - SDO_random,3)`. It is not equal to zero because our sample size is not large enough to completely negate random variations in the two group's differences.

4\. *To do at home*:  Compute the value of the ***selection bias*** and the ***heterogenous treatment effect bias*** and check that we have $$SDO = ATE + \textrm{selection bias} + \textrm{heterogenous treatment effect bias}$$

```{r}
selection_bias = mean(toy_data$Y0[toy_data$group == "treatment"]) - mean(toy_data$Y0[toy_data$group == "control"])

het_trt_effect_bias = (1 - sum(toy_data$group == "treatment") / nrow(toy_data)) * (mean(toy_data$delta[toy_data$group == "treatment"]) - mean(toy_data$delta[toy_data$group == "control"]))

SDO
ATE + selection_bias + het_trt_effect_bias
```


## Task 2: STAR data

1\. Load the *STAR* data from [here](https://github.com/adamsoliman/IntroEconometrics/blob/master/data%20for%20tasks/star_data.csv) and assign it to an object called `star_df`.

```{r}
# remember to change the path
star_df <- read.csv("/Users/adamsoliman/Documents/GitHub/Econometrics-Slides/data for tasks/star_data.csv")
```

2\. What's the unit of observation? Which variable contains: (i) the (random) class assignment, (ii) the student's class grade, (iii) the outcomes of interest?

**The unit of observation is student-grade. The variable containing the (random) class assignment is `star`, that containing the student's class grade is `grade`, and that containing the outcomes of interest are `read` and `math`.**

3\. How many observations are there? Why so many?

**There are so many observations because the data has been reshaped such that each row corresponds to a student in a grade rather than just to a student.**

4\. Why are there so many `NA`s? What do they correspond to?

**The `NA`s correspond to children who left the experiment for various reasons. This is called attrition.**

5\. Keep only cases with no `NA`s with the following code:  
`star_df_complete <- star_df %>% filter(complete.cases(.))`

```{r}
star_df_complete <- star_df %>% filter(complete.cases(.))
```

7\. Let's check how well the randomization was done by doing ***balancing checks***.  
Compute the average percentage of girls, african americans, and free lunch qualifiers by grade *and* treatment class. (*Hint*: The following computes the percentage of girls (without the relevant `dplyr` verbs):
`share_female = mean(gender == "female") * 100`.)

```{r}
star_df_complete %>%
  mutate(is_female = ifelse(gender == "female", 1, 0),
        is_african_american = ifelse(ethnicity == "afam", 1, 0),
        is_free_lunch = ifelse(lunch == "free", 1, 0)) %>%
    group_by(grade, star) %>%
    summarise(share_female = sum(is_female) / n() * 100,
              share_african_american = sum(is_african_american) / n() * 100,
              share_free_lunch = sum(is_free_lunch) / n() * 100)

# alternative way
balancetest <- star_df_complete %>%
    group_by(grade, star) %>%
    summarise(share_female = mean(gender == "female") * 100,
              share_african_american = mean(ethnicity == "afam") * 100,
              share_free_lunch = mean(lunch == "free") * 100)
balancetest
```

