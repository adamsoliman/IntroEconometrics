---
title: "Multiple Linear Regression - Tasks"
author: "Dr. Soliman"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Task 1

Let's analyse the regression results using **reading** score as the dependent variable.

1. Load the data from [here](https://www.dropbox.com/scl/fi/77u2r8xznh63jg7aisq4f/grade5_isl.csv?rlkey=uclo7ng24so9fct41kcjm8k0l&dl=1) as `grades`.

```{r}
# your path will look different
grades <- read.csv("/Users/adamsoliman/Library/CloudStorage/Dropbox/Clemson/Econometrics Course/data for tasks/grade5_isl.csv")
```

1\. Regress `avgverb` on `classize` and `disadvantaged` and assign the output to a new object `reg`. Interpret the coefficients. How do they compare with the math score regression coefficients?

```{r}
reg <- lm(avgverb ~ classize + disadvantaged, grades)
reg
```

**The intercept, which measures that expected reading score when class size and the percentage of disadvantaed students in the class are 0, equals 80. This, as we've discussed in class, doesn't make any "real-world" sense because if there are no students then there cannot be a test score. The coefficient on class size is -0.03 which means that a 1 student increase in class size, controlling for the percentage of disadvantaged students, is, on average, associated to a 0.03 point decrease in average reading score. The coefficient is negative while it was positive when analysing math score as the outcome. However, the coefficient is very small considering reading is scored on a scale from 0 to 100. Lastly, the coefficient on disadvantaged is equal to -0.35 which means that keeping class size constrant, a 1 percentage point increase in disadvantaged students is associate, on average, with a 0.35 point decrease in averate reading score. The magnitude of this coefficient is very similar to that when looking at math scores. Again, it is very small: a 10 percentage point increase in disadvantaged students (quite a large increase) would only be associated, on average, with 3.5 points decrease in reading score, keeping class size constant.**

1\. What are the other available variables that we may add in the regression? 
  * Run the regression with all these variables and assign it to `reg_full`.
  * Look at the coefficients.
  * Discuss all coefficients: sign and magnitude.
  
```{r}
reg_full <- lm(avgverb ~ classize + disadvantaged + school_enrollment + female + religious, grades)
reg_full
```

## Task 2: Dummy Variable Trap

Still need to think about this dummy variable trap? Let's run another regression where there is perfect linear dependence between regressors.

1\. Load the *STAR* data from [here]("https://www.dropbox.com/s/bf1fog8yasw3wjj/star_data.csv?dl=1"), using `read.csv`, and assign it to an object called `star_df`. Keep only cases with no `NA`s.

```{r}
library(tidyverse)

star_df <- read.csv("/Users/adamsoliman/Library/CloudStorage/Dropbox/Clemson/Econometrics Course/data for tasks/star_data.csv")
star_df_complete <- star_df %>% filter(complete.cases(.))
```

2\. Create three dummy variables: (i) `small` equal to `TRUE` if students are in a small class and `FALSE` otherwise; (ii) `regular` equal to `TRUE` if students are in a regular class and `FALSE` otherwise; (iii) `regular_plus` equal to `TRUE` if students are in a regular+aide class and `FALSE` otherwise. Create a last variable, `sum`, equal to the sum of `small`, `regular` and `regular_plus`. What is `sum` equal to? What does this mean?

```{r}
star_df_complete <- star_df_complete %>%
    mutate(small = (star == "small"),
           regular = (star == "regular"),
           regular_plus = (star == "regular+aide"),
           sum = small + regular + regular_plus)

star_df_complete %>% count(sum)
```

**The `sum` variable is always equal to 1, which means that `small`, `regular` and `regular_plus` are perfectly collinear. In other words they can be expressed as a linear combination of each one of another, i.e. `small` = 1 - (`regular` + `regular_plus`).**

3\. Regress `math` on `small`. What is the average predicted `math` score of students in a small class? Do the same for `regular` and `regular_plus`.

```{r}
reg_small <- lm(math ~ small, star_df_complete)
reg_small
```

**Note that our regressor is a dummy variable. Remember from the lecture on causality that when the regressor is a dummy variable, the intercept corresponds to the conditional mean of outcome variable for the `FALSE` category while the slope coefficient corresponds to the difference in expected outcomes between the `TRUE` and the `FALSE` category. In this case, from the regression, we can get that the expected math score of students not in a small class is around `r round(reg_small$coefficients[1],2)` points , and that the difference in expected math score between students in a small class and those not in a small class is 10.29 points. As such, the expected math score of students in a small class is approximately `r round(reg_small$coefficients[1],2)` + `r round(reg_small$coefficients[2],2)` = `r round(reg_small$coefficients[1] + reg_small$coefficients[2],2)`.**

**For those of you who prefer seeing this formally, this is how you can (should proceed):**
$$
\mathbb{E}(\text{math score } | \text{ small} = 0) = b_0 + b_1 \times 0 = b_0 \approx `r round(reg_small$coefficients[1],2)` \\
\mathbb{E}(\text{math score } | \text{ small} = 1) = b_0 + b_1 \times 1 = b_0 + b_1 \approx `r round(reg_small$coefficients[1] + reg_small$coefficients[2],2)`
$$

```{r}
reg_regular <- lm(math ~ regular, star_df_complete)
reg_regular

reg_plus <- lm(math ~ regular_plus, star_df_complete)
reg_plus
```

**Using the exact same logic as above, we obtain:**
$$
\mathbb{E}(\text{math score } | \text{ regular} = 0) = b_0 + b_1 \times 0 = b_0 \approx `r round(reg_regular$coefficients[1],2)` \\
\mathbb{E}(\text{math score } | \text{ regular} = 1) = b_0 + b_1 \times 1 = b_0 + b_1 \approx `r round(reg_regular$coefficients[1] + reg_regular$coefficients[2],2)` \\
\mathbb{E}(\text{math score } | \text{ regular+aide} = 0) = b_0 + b_1 \times 0 = b_0 \approx `r round(reg_plus$coefficients[1],2)` \\
\mathbb{E}(\text{math score } | \text{ regular+aide} = 1) = b_0 + b_1 \times 1 = b_0 + b_1 \approx `r round(reg_plus$coefficients[1] + reg_plus$coefficients[2],2)`
$$


4\. Regress `math` on `small`, `regular` and `regular_plus`. What do you notice? What's the omitted (reference) category? Does this match the previous questions?

```{r}
reg_full <- lm(math ~ small + regular + regular_plus, star_df_complete)
reg_full
```

**We notice that the `regular_plus` variable has been dropped, i.e. the coefficient for this variable cannot be estimated because it is collinear to `small` and `regular`. This means that the reference category is regular+aide. In other words, the coefficients on `small` and `regular` are to be interpreted relative to the outcomes of the regular+aide students. To be specific, and using the same formal interpretation as above, denoting the model as $\text{math score} = b_0 + b_1 \text{small} + b_2 \text{regular} + e$, we obtain:**

\begin{align}
b_0 &= \mathbb{E}(\text{math score } | \text{ small} = 0 \text{ & } \text{ regular} = 0) \\
&= \mathbb{E}(\text{math score } | \text{ regular + aide} = 1) \\
&\approx `r round(reg_full$coefficients[1],2)`
\end{align}

You can compare this resul with the answer to the previous question and see that we obtain exactly the same answer.

In the same way, we get:

\begin{align}
b_1 &= \mathbb{E}(\text{math score } | \text{ small} = 1 \text{ & } \text{ regular} \in \{0,1\}) - \mathbb{E}(\text{math score } | \text{ small} = 0 \text{ & } \text{ regular} \in \{0,1\}) \\
&= b_0 + b_1 \times 1 + b_2 \times \text{regular} - (b_0 + b_1 \times 0 + b_2 \times \text{regular}) \\
&\approx `r round(reg_full$coefficients[2],2)`
\end{align}

\begin{align}
b_2 &= \mathbb{E}(\text{math score } | \text{ small} \in \{0,1\} \text{ & } \text{ regular} = 1) - \mathbb{E}(\text{math score } | \text{ small} \in \{0,1\} \text{ & } \text{ regular} = 0) \\
&= b_0 + b_1 \times \text{small} + b_2 \times 1 - (b_0 + b_1 \times \text{small} + b_2 \times 0) \\
&\approx `r round(reg_full$coefficients[3],2)`
\end{align}

In plain English, the interpretation is that relative to the regular+aide group, students in small classes score 6.25 points higher in the math exam, while relative to the regular+aide group, students in regular classes score 2.7 points lower in the math exam.

5\. Regress `math` on `star`. What do you notice? What's the omitted category? Interpret the coefficient.

```{r}
lm(math ~ star, star_df_complete)
```

**`R` actually creates the dummy variables for me, I don't need to do the tedious work above of creating an individual dummy variable for each category! The omitted category is `regular` therefore the coefficients are to be interpreted as differences in average math scores relative to students in `regular` classes.**

